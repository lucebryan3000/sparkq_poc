# Codex Integration for SparkQueue

SparkQueue uses Codex to draft API/CLI changes while keeping storage and queue semantics consistent. This guide maps the codebase and explains which generation patterns to use.

## Directory layout
- `.codex/README.md`: project-specific Codex guide (this file)
- `.codex/prompts/README.md`: prompt patterns tailored to SparkQueue
- `.codex/cache/`, `.codex/temp/`: throwaway generations and logs (gitignored)
- `.codex/generated/`: optional staging area for generated snippets before you copy reviewed changes into the repo

## Integration map (where Codex should target)
- **API service**: `sparkq/src/api.py` (FastAPI routes for health, sessions, streams, tasks, quick-add). Serves UI from `sparkq/ui`.
- **CLI**: `sparkq/src/cli.py` (Typer commands for setup, enqueue/peek/claim/complete, server lifecycle). Uses `_handle_exception` and `get_storage()`.
- **Server runner**: `sparkq/src/server.py` (uvicorn wrapper, lockfile coordination, auto-purge/auto-fail threads).
- **Storage**: `sparkq/src/storage.py` (SQLite DDL/queries, ID helpers, purge/auto-fail routines).
- **Models**: `sparkq/src/models.py` (Pydantic models/enums shared by API, CLI, and tests).
- **Scripts & tools**: `sparkq/src/index.py` (script discovery) and `sparkq/src/tools.py` (tool registry from `sparkq.yml`).
- **Docs & UI**: API reference in `sparkq/docs/API.md`, dashboard assets in `sparkq/ui`.

## How to use Codex here
1. Pick the prompt pattern from `.codex/prompts/README.md` that matches the task (API endpoint, CLI command, task-queue/storage behavior).
2. Generate drafts into `.codex/generated/<feature>/` so reviewers can diff curated commits against machine output.
3. Move only reviewed code into `sparkq/src` or `sparkq/tests`; leave scratch files ignored in `.codex/generated/` or `.codex/temp/`.
4. Keep generations small and focused (one module per run). Reuse existing helpers: `_serialize_task` for API responses, `_emit_error`/`_handle_exception` for CLI, `Storage` methods for data access, and `now_iso()` for timestamps.

## Generated code patterns to pick
- **Task queue operations**: use the task-queue/storage prompt when adjusting auto-fail/auto-purge logic, task lifecycle, or SQL queries. Keep mutations in `Storage` and normalize timestamps with `now_iso()`.
- **API endpoints (FastAPI)**: use the API prompt when adding routes; rely on Pydantic request models, reuse `_serialize_task`, and keep error responses consistent with `_error_response`.
- **CLI commands (Typer)**: use the CLI prompt when creating new commands; fetch storage via `get_storage()`, wrap exceptions with `_handle_exception`, and mirror API behavior.
- **Config or tool discovery**: when updating script discovery or tool registry behavior, mention `sparkq.yml` defaults and keep parsing in `index.py` or `tools.py`.

## Guardrails
- Prefer updating `sparkq/docs/API.md` alongside API changes so prompts stay aligned with docs.
- Keep generated logs in `.codex/cache/` and long-form drafts in `.codex/temp/`; both are ignored.
- If you checkpoint generated code in the repo temporarily, tag it with a brief comment such as `# Generated by Codex: review before editing` and replace it after manual review.
